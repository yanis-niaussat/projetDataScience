
# üö® PROJET DATA SCIENCE : Mod√©lisation Inondation Loire-Sully (IRSN)

**Objectif :** Remplacer un simulateur hydraulique lent (Telemac) par un mod√®le d'IA instantan√©.
**Deadline :** Vendredi prochain (Urgence absolue).
**Strat√©gie :** "Le Grand Tournoi des Familles". On compare les 3 grandes approches du ML (Lin√©aire, Ensembliste, Connexionniste).

---

## üìç √âTAPE 0 : LA "GOLDEN DATA" (URGENT - CE WEEK-END)

Avant de coder quoi que ce soit, nous devons g√©n√©rer un fichier unique **`dataset_final_Sully.csv`** propre et partag√©.

### 1. Structure du Dataset
* **Entr√©es (X - 8 colonnes) :** Extraites du nom des fichiers (`er`, `ks2`, `ks3`, `ks4`, `ks_fp`, `of`, `qmax`, `tm`).
* **Sorties (Y - 4 colonnes) :** Hauteurs d'eau extraites des matrices CSV aux coordonn√©es suivantes (Valid√©es hydrauliquement) :

| Point d'int√©r√™t (Target) | Indice Ligne (X) | Indice Colonne (Y) | Description |
| :--- | :---: | :---: | :--- |
| **Parc_Chateau** | 27 | 50 | Zone critique (Bord de Loire) |
| **Centre_Sully** | 18 | 42 | Centre-ville |
| **Gare_Sully** | 16 | 28 | Zone urbaine interm√©diaire |
| **Caserne_Pompiers** | 12 | 11 | Zone "s√®che" / √©loign√©e |

> **‚ö†Ô∏è Attention :** Les indices sont donn√©s pour une matrice Python/R standard. Si vous utilisez `pandas` ou `numpy`, v√©rifiez bien l'orientation (Ligne=X, Colonne=Y).

---

## ‚öôÔ∏è √âTAPE 1 : LE PROTOCOLE TECHNIQUE (LOI MARTIALE)

Pour que nous puissions comparer nos r√©sultats Mercredi, **tout le monde doit utiliser EXACTEMENT ce code de d√©part.** Copiez-collez ceci dans vos Notebooks respectifs.

### 1. Split Train/Test (Inviolable)
On ne touche **JAMAIS** au `X_test` pour r√©gler les mod√®les. C'est le juge de paix final.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Chargement
df = pd.read_csv("dataset_final_Sully.csv")
X = df[['er', 'ks2', 'ks3', 'ks4', 'ks_fp', 'of', 'qmax', 'tm']]
y = df[['Parc_Chateau', 'Centre_Sully', 'Gare_Sully', 'Caserne_Pompiers']]

# SPLIT : random_state=42 est OBLIGATOIRE pour qu'on ait les m√™mes donn√©es
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SCALING : Important pour Neural Net et Lasso/Ridge
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

```

### 2. Strat√©gie de Mod√©lisation (Boucle simple)

Ne faites pas de "Multi-Output" natif complexe. Faites une boucle simple sur les 4 lieux.

```python
targets = ['Parc_Chateau', 'Centre_Sully', 'Gare_Sully', 'Caserne_Pompiers']
results = {}

for lieu in targets:
    print(f"Training for {lieu}...")
    # S√©lection de la colonne cible
    y_train_col = y_train[lieu]
    
    # Votre mod√®le ici (Exemple)
    # model.fit(X_train_scaled, y_train_col)
    
    # Sauvegarde
    # results[lieu] = model

```

---

## üë• √âTAPE 2 : R√âPARTITION DES R√îLES

Chacun est responsable d'une famille d'algorithmes.

### üë§ Fatima : "Linear Expert" (Statistique & Cours)

* **Mission :** Prouver qu'on a √©cout√© le prof et offrir de l'interpr√©tabilit√©.
* **Algorithmes :**
1. **Linear Regression :** Score de r√©f√©rence (Baseline).
2. **Ridge () :** G√©rer la corr√©lation entre les variables `ks`.
3. **Lasso () :** **CRUCIAL.** Identifier les variables inutiles (coef = 0).


* **Livrable cl√© :** "Quelles variables physiques le Lasso a-t-il supprim√©es ?"
* **Librairie :** `sklearn.linear_model`

### üë§ Marius : "Bagging Expert" (Robustesse)

* **Mission :** Fournir un mod√®le stable, robuste et difficile √† prendre en d√©faut (Overfitting faible).
* **Algorithmes :**
1. **Random Forest Regressor :** La valeur s√ªre.


* **Approche :** M√©thode ensembliste parall√®le (moyenne des arbres).
* **Livrable cl√© :** Le graphique de **Feature Importance** (Quelle variable physique cause l'inondation ?).
* **Librairie :** `sklearn.ensemble`

### üë§ Tom : "Boosting Expert" (Performance Pure)

* **Mission :** Aller chercher la pr√©cision maximale (Comp√©tition Kaggle).
* **Algorithmes :**
1. **XGBoost :** Le challenger agressif.


* **Approche :** M√©thode ensembliste s√©quentielle (correction des erreurs pr√©c√©dentes).
* **Attention :** Bien installer la librairie (`pip install xgboost`).
* **Librairie :** `xgboost`

### üë§ Yanis : "Neural Expert" (Deep Learning & Viz)

* **Mission :** Capturer les non-lin√©arit√©s complexes avec une approche connexionniste.
* **Algorithmes :**
1. **MLP Regressor :** R√©seau de neurones (ex: 2 couches cach√©es de 100 neurones). Solver='adam'.


* **Mission Transverse :** Mercredi, tu r√©cup√®res les pr√©dictions des 3 autres sur le `X_test` et tu traces les graphiques comparatifs ("R√©el vs Pr√©dit").
* **Librairie :** `sklearn.neural_network`

---

## üìÖ √âTAPE 3 : LA ROADMAP DE SURVIE

| Timing | Action | Responsable |
| --- | --- | --- |
| **Ce Weekend** | G√©n√©rer `dataset_final_Sully.csv` et le mettre sur le Drive/Git. | **Membre 1** |
| **Lundi** | Coder son mod√®le (V1) qui tourne sans erreur. | **Tous** |
| **Mardi** | **Tuning (Cross-Validation).** Chacun optimise ses hyperparam√®tres sur `X_train`. | **Tous** |
| **Mercredi** | **LE GRAND MERGE.** On met tout dans un tableau comparatif. On fige les r√©sultats. | **Membre 4** (Lead) |
| **Jeudi** | R√©daction Rapport & Slides. (Interpr√©tation Physique > Code). | **Tous** |
| **Vendredi** | **Rendu / Soutenance.** | **Tous** |

---

## üìù STRUCTURE DU RAPPORT (Suggestion)

1. **Contexte :** Pourquoi l'IA ? (Acc√©l√©rer Telemac).
2. **Data Engineering :** Validation hydraulique des points (coordonn√©es).
3. **Approche Statistique (Cours) :** Lasso/Ridge (S√©lection de variables).
4. **Approche Ensembliste (Le Match) :** Bagging (Random Forest) vs Boosting (XGBoost). Qui gagne ?
5. **Approche Connexionniste :** R√©seau de Neurones (Capacit√© de g√©n√©ralisation).
6. **Conclusion :** Tableau final des scores. Recommandation pour l'IRSN.
* *Ouverture : "Pour aller plus loin, nous pourrions tester le Kriging (Processus Gaussiens) pour quantifier l'incertitude."*



üöÄ **Allez l'√©quipe, on vise le 18/20 !**

```